""" --working version--
1) augmented dataset, 40 classes version one by one
2) work in mutiple models
3) adding CGAN , now DCGAN and CGAN
4) add reconstraction loss L1_loss
"""

from DCGAN import DCGAN
from CGAN import CGAN
import argparse
from utils import *

"""
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0,1,2"
"""

"""parsing and configuration"""
def parse_args():
    desc = "Tensorflow implementation of Self-Attention GAN"
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('--phase', type=str, default='train', help='train or test ?')
    parser.add_argument('--dataset', type=str, default='n02510455', help='[mnist / cifar10 / celebA]')
    parser.add_argument('--augment_flag', type=str, default=True, help='using augmented dataset')

    parser.add_argument('--model_name', type=str, default='DCLS-GAN',
                        choices=['GAN', 'CGAN', 'infoGAN', 'ACGAN', 'EBGAN', 'BEGAN', 'WGAN', 'WGAN_GP', 'DRAGAN', 'LSGAN', 'VAE', 'CVAE'],
                        help='The type of GAN')

    parser.add_argument('--epoch', type=int, default=50, help='The number of epochs to run')
    parser.add_argument('--iteration', type=int, default=10000, help='The number of training iterations')
    parser.add_argument('--batch_size', type=int, default=32, help='The size of batch per gpu')
    parser.add_argument('--print_freq', type=int, default=500, help='The number of image_print_freqy')
    parser.add_argument('--save_freq', type=int, default=500, help='The number of ckpt_save_freq')


    parser.add_argument('--g_lr', type=float, default=0.0001, help='learning rate for generator')
    parser.add_argument('--d_lr', type=float, default=0.0004, help='learning rate for discriminator')
    parser.add_argument('--beta1', type=float, default=0.0, help='beta1 for Adam optimizer')
    parser.add_argument('--beta2', type=float, default=0.9, help='beta2 for Adam optimizer')

    parser.add_argument('--adv_w', type=float, default=1.0, help='weight of adversarial loss')
    parser.add_argument('--recon_w', type=float, default=1.0, help='weight of recon loss')

    parser.add_argument('--y_dim', type=int, default=128, help='Dimension of decoder vector')
    parser.add_argument('--z_dim', type=int, default=128, help='Dimension of noise vector')
    parser.add_argument('--up_sample', type=str2bool, default=True, help='using upsample-conv')
    parser.add_argument('--sn', type=str2bool, default=False, help='using spectral norm')
    parser.add_argument('--gan_type', type=str, default='hinge', help='[gan / lsgan / wgan-gp / wgan-lp / dragan / hinge]')
    parser.add_argument('--ld', type=float, default=10.0, help='The gradient penalty lambda')
    parser.add_argument('--n_critic', type=int, default=1, help='The number of critic')

    parser.add_argument('--img_size', type=int, default=128, help='The size of image')
    parser.add_argument('--sample_num', type=int, default=64, help='The number of sample images')


    parser.add_argument('--test_num', type=int, default=10, help='The number of images generated by the test')


    parser.add_argument('--checkpoint_dir', type=str, default='checkpoint',
                        help='Directory name to save the checkpoints')
    parser.add_argument('--result_dir', type=str, default='results',
                        help='Directory name to save the generated images')
    parser.add_argument('--log_dir', type=str, default='logs',
                        help='Directory name to save training logs')
    parser.add_argument('--sample_dir', type=str, default='samples',
                        help='Directory name to save the samples on training')
    parser.add_argument('--gen_dir', type=str, default='gens',
                        help='Directory name to save the generated images')
    parser.add_argument('--gen_all_dir', type=str, default='gens_all',
                        help='Directory name to save the generated images')

    return check_args(parser.parse_args())

"""checking arguments"""
def check_args(args):
    # --checkpoint_dir
    check_folder(args.checkpoint_dir)

    # --result_dir
    check_folder(args.result_dir)

    # --result_dir
    check_folder(args.log_dir)

    # --sample_dir
    check_folder(args.sample_dir)

    # --gen_dir
    check_folder(args.gen_dir)

    # --gen_all_dir
    check_folder(args.gen_all_dir)

    # --epoch
    try:
        assert args.epoch >= 1
    except:
        print('number of epochs must be larger than or equal to one')

    # --batch_size
    try:
        assert args.batch_size >= 1
    except:
        print('batch size must be larger than or equal to one')
    return args


"""main"""
def main():
    # parse arguments
    args = parse_args()
    if args is None:
      exit()

    # datasets
    models = [DCGAN, CGAN]
    datasets = ['n02106662',
                'n02124075',
                'n02281787',
                'n02389026',
                'n02492035',
                'n02504458',
                'n02510455',
                'n02607072',
                'n02690373',
                'n02906734',
                'n02951358',
                'n02992529',
                'n03063599',
                'n03100240',
                'n03180011',
                'n03197337',
                'n03272010',
                'n03272562',
                'n03297495',
                'n03376595',
                'n03445777',
                'n03452741',
                'n03584829',
                'n03590841',
                'n03709823',
                'n03773504',
                'n03775071',
                'n03792782',
                'n03792972',
                'n03877472',
                'n03888257',
                'n03982430',
                'n04044716',
                'n04069434',
                'n04086273',
                'n04120489',
                'n07753592',
                'n07873807',
                'n11939491',
                'n13054560']

    for dataset in datasets:
        args.dataset = dataset
        # open session
        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:
            gan = None

            for model in models:
                if args.model_name == model.model_name:
                    gan = model(sess, args)
            if gan is None:
                raise Exception("[!] There is no option for " + args.model_type)

            # build graph
            gan.build_model()

            # show network architecture
            show_all_variables()

            if args.phase == 'train' :
                # launch the graph in a session
                gan.train()

                # visualize learned generator
                gan.visualize_results(args.epoch - 1)

                print(" [*] Training finished!")

            if args.phase == 'test' :
                gan.test()
                print(" [*] Test finished!")

            if args.phase == 'gen':
                gan.gen()
                print(" [*] Generation finished!")

            if args.phase == 'gen_all':
                gan.gen_all()
                print(" [*] Generation all finished!")
        tf.reset_default_graph()

if __name__ == '__main__':
    main()
